{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting Stuff Up</h2>\n",
    "\n",
    "Here we import some packages that we'll need in various places. We'll also load all the variables we set in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/agave\n",
    "\n",
    "%cd ~/agave\n",
    "\n",
    "!pip3 install --upgrade setvar\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from agavepy.agave import Agave\n",
    "from setvar import *\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "# This cell enables inline plotting in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "setvar(\"\"\"\n",
    "AGAVE_APP_NAME=training-${AGAVE_USERNAME}\n",
    "AGAVE_STORAGE_SYSTEM_ID=sandbox-storage-${AGAVE_USERNAME}\n",
    "AGAVE_EXECUTION_SYSTEM_ID=sandbox-exec-${AGAVE_USERNAME}\n",
    "AGAVE_SYSTEM_SITE_DOMAIN=localdomain\n",
    "MACHINE_NAME=sandbox\n",
    "MACHINE_USERNAME=jovyan\n",
    "AGAVE_STORAGE_HOME_DIR=/home/${MACHINE_USERNAME}\n",
    "SCRATCH_DIR=/home/${MACHINE_USERNAME}\n",
    "AGAVE_STORAGE_WORK_DIR=/home/${MACHINE_USERNAME}\n",
    "AGAVE_APP_DEPLOYMENT_PATH=agave-deploy\n",
    "\"\"\")\n",
    "loadvar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the CLI\n",
    "\n",
    "If you are running against a privately hosted Agave tenant, you need to configure the tutorial to run against your tenant. You can do that by setting the `AGAVE_TENANTS_API_BASEURL` and `AGAVE_TENANT_ID` environment variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you specified the correct address to your Tenants API, you should be able to discover the tenants available for you through the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tenants-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tenant you would like to use by setting the `AGAVE_TENANT` environment variable. You may select either the name of the tenant, or leave it blank to select the default tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tenants-init -t sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Client API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step we delete the client if it exists. Chances are, yours doesn't yet. We put this command here in case, for some reason, you want to re-create your client later on. If you delete the client you intend to create before you create it, no harm is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clients-delete -u \"$AGAVE_USERNAME\" -p \"$AGAVE_PASSWORD\" $AGAVE_APP_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we create the client. Clients provide a way of encapsulating resources connected to a single project. Through the client, you will receive a token which you can use to run most of the Agave commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clients-create -u \"$AGAVE_USERNAME\" -p \"$AGAVE_PASSWORD\" -N \"$AGAVE_APP_NAME\" -S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the token for your client. You will, from this point on, use this token to run the remainder of the Agave commands in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!auth-tokens-create -u $AGAVE_USERNAME -p \"$AGAVE_PASSWORD\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOLLOWING ALONG AT HOME  \n",
    "\n",
    "If you are following along at home using the docker-compose stack, you will need to run the following cell to get the hostname and port of your tcp tunnel so Agave can contact your system without a public IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get('USE_TUNNEL') == 'True': \n",
    "    # fetch the hostname and port of the reverse tunnel running in the sandbox \n",
    "    # so Agave can connect to our local sandbox\n",
    "    !echo $(ssh -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null sandbox 'curl -s  http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url'') > ngrok_url.txt  \n",
    "    !cat ngrok_url.txt | sed 's|^tcp://||'\n",
    "    !cat ngrok_url.txt | sed 's|^tcp://||' | sed -r 's#(.*):(.*)#\\1#' > ngrok_host.txt\n",
    "    !cat ngrok_url.txt | sed 's|^tcp://||' | sed -r 's#(.*):(.*)#\\2#' > ngrok_port.txt\n",
    "\n",
    "    # set the environment variables otherwise set when running in a training cluster\n",
    "    os.environ['VM_PORT'] = readfile('ngrok_port.txt').strip()\n",
    "    os.environ['VM_MACHINE'] = readfile('ngrok_host.txt').strip()\n",
    "    os.environ['AGAVE_SYSTEM_HOST'] = readfile('ngrok_host.txt').strip()\n",
    "    os.environ['AGAVE_SYSTEM_PORT'] = readfile('ngrok_port.txt').strip()\n",
    "    !echo \"VM_PORT=$VM_PORT\"\n",
    "    !echo \"VM_MACHINE=$VM_MACHINE\"\n",
    "    setvar(\"VM_IPADDRESS=$(getent hosts ${VM_MACHINE}|cut -d' ' -f1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Storage System   \n",
    "\n",
    "Agave wants to know which place (or places) you want to store the data associated with your jobs. Here, we're going to set that up. Authentication to the storage machine will be through SSH keys. The key and public key files, however, contain newlines. To encode them in Json (the data format used by Agave), we will run the jsonpki command on each file. Next, we will store its contents in the environment for use by setvar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/key\n",
    "!chmod 700 ~/key\n",
    "!jsonpki --public ~/.ssh/id_rsa.pub > ~/key/id_rsa.pub.txt\n",
    "!jsonpki --private ~/.ssh/id_rsa > ~/key/id_rsa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PUB_KEY\"]=readfile(\"${HOME}/key/id_rsa.pub.txt\").strip()\n",
    "os.environ[\"PRIV_KEY\"]=readfile(\"${HOME}/key/id_rsa.txt\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we create the json file used to describe the storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"${AGAVE_STORAGE_SYSTEM_ID}.txt\",\"\"\"{\n",
    "    \"id\": \"${AGAVE_STORAGE_SYSTEM_ID}\",\n",
    "    \"name\": \"${MACHINE_NAME} storage (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${AGAVE_SYSTEM_SITE_DOMAIN}\",\n",
    "    \"type\": \"STORAGE\",\n",
    "    \"storage\": {\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${AGAVE_STORAGE_HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tell Agave about the machine. You can re-run the previous cell and the next one if you want to change the definition of your storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!systems-addupdate -F ${AGAVE_STORAGE_SYSTEM_ID}.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the Agave command `files-list`. This provides a check that we've set up the storage machine correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-list -l 5 -S ${AGAVE_STORAGE_SYSTEM_ID} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Execution System\n",
    "\n",
    "You may not always wish to store your data on the same machine you run your jobs on. However, in this tutorial, we will assume that you do. The description for the execution machine is much like the storage machine. However, there are a few more pieces of information you'll need to provide. In this example, we are going to call commands directly on the host as opposed to using a batch queue scheduler. It is slightly simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit any parts of this file that you know need to be changed for your machine.\n",
    "writefile(\"${AGAVE_EXECUTION_SYSTEM_ID}.txt\",\"\"\"\n",
    "{\n",
    "    \"id\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "    \"name\": \"${MACHINE_NAME} (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${AGAVE_SYSTEM_SITE_DOMAIN}\",\n",
    "    \"public\": false,\n",
    "    \"status\": \"UP\",\n",
    "    \"type\": \"EXECUTION\",\n",
    "    \"executionType\": \"CLI\",\n",
    "    \"scheduler\" : \"FORK\",\n",
    "    \"environment\": null,\n",
    "    \"scratchDir\" : \"${SCRATCH_DIR}\",\n",
    "    \"queues\": [\n",
    "        {\n",
    "            \"name\": \"none\",\n",
    "            \"default\": true,\n",
    "            \"maxJobs\": 10,\n",
    "            \"maxUserJobs\": 10,\n",
    "            \"maxNodes\": 6,\n",
    "            \"maxProcessorsPerNode\": 6,\n",
    "            \"minProcessorsPerNode\": 1,\n",
    "            \"maxRequestedTime\": \"00:30:00\"\n",
    "        }\n",
    "    ],\n",
    "    \"login\": {\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        },\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SSH\"\n",
    "    },\n",
    "    \"maxSystemJobs\": 50,\n",
    "    \"maxSystemJobsPerUser\": 50,\n",
    "    \"storage\": {\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${AGAVE_STORAGE_HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    },\n",
    "    \"workDir\": \"${AGAVE_STORAGE_WORK_DIR}\"\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!systems-addupdate -F ${AGAVE_EXECUTION_SYSTEM_ID}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if this worked...\n",
    "!files-list -l 5 -S ${AGAVE_EXECUTION_SYSTEM_ID} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your First App\n",
    "\n",
    "Agave allows us to describe custom allocations, limiting users to run a specific job. In this case, we're going to create a simple \"fork\" scheduler that just takes the command we want to run as a job parameter. The wrapper file is a shell script we will run on the execution machine. If we were using a scheduler, this would be our batch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"fork-wrapper.txt\",\"\"\"\n",
    "#!/bin/bash\n",
    "\\${command}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Agave commands, we make a directory on the storage server an deploy our wrapper file there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N ${AGAVE_APP_DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-wrapper.txt -S ${AGAVE_STORAGE_SYSTEM_ID} ${AGAVE_APP_DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All agave applications require a test file. The test file is a free form text file which allows you to specify what resources you might need to test your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"fork-test.txt\",\"\"\"\n",
    "command=date\n",
    "fork-wrapper.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N ${AGAVE_APP_DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-test.txt -S ${AGAVE_STORAGE_SYSTEM_ID} ${AGAVE_APP_DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like everything else in Agave, we describe our application with Json. We specifiy which machines the application will use, what method it will use for submitting jobs, job parameters and files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"fork-app.txt\",\"\"\"\n",
    "{  \n",
    "   \"name\":\"${AGAVE_USERNAME}-${MACHINE_NAME}-fork\",\n",
    "   \"version\":\"1.0\",\n",
    "   \"label\":\"Runs a command\",\n",
    "   \"shortDescription\":\"Runs a command\",\n",
    "   \"longDescription\":\"\",\n",
    "   \"deploymentSystem\":\"${AGAVE_STORAGE_SYSTEM_ID}\",\n",
    "   \"deploymentPath\":\"${AGAVE_APP_DEPLOYMENT_PATH}\",\n",
    "   \"templatePath\":\"fork-wrapper.txt\",\n",
    "   \"testPath\":\"fork-test.txt\",\n",
    "   \"executionSystem\":\"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"executionType\":\"CLI\",\n",
    "   \"parallelism\":\"SERIAL\",\n",
    "   \"modules\":[],\n",
    "   \"inputs\":[\n",
    "         {   \n",
    "         \"id\":\"datafile\",\n",
    "         \"details\":{  \n",
    "            \"label\":\"Data file\",\n",
    "            \"description\":\"\",\n",
    "            \"argument\":null,\n",
    "            \"showArgument\":false\n",
    "         },\n",
    "         \"value\":{  \n",
    "            \"default\":\"/dev/null\",\n",
    "            \"order\":0,\n",
    "            \"required\":false,\n",
    "            \"validator\":\"\",\n",
    "            \"visible\":true\n",
    "         }\n",
    "      }   \n",
    "   ],\n",
    "   \"parameters\":[{\n",
    "     \"id\" : \"command\",\n",
    "     \"value\" : {\n",
    "       \"visible\":true,\n",
    "       \"required\":true,\n",
    "       \"type\":\"string\",\n",
    "       \"order\":0,\n",
    "       \"enquote\":false,\n",
    "       \"default\":\"/bin/date\",\n",
    "       \"validator\":null\n",
    "     },\n",
    "     \"details\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     },\n",
    "     \"semantics\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     }\n",
    "   }],\n",
    "   \"outputs\":[]\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apps-addupdate -F fork-app.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running  Jobs\n",
    "\n",
    "Now that we have specified our application using Agave, it is time to try running jobs. To start a job we, once again, create a Json file. The Json file describes the app, what resource to run on, as well as how and when to send notifications. Notifications are delivered by callback url. EMAIL is the easiest type to configure, but we show here how to send webhook notifications to the popular [RequestBin](https://requestb.in/). \n",
    "\n",
    "Before we configure our notification, we need to create a requestbin to use. There are convenience commands to interact with requestbin built into the Agave CLI. We will use those to get our URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rburl = !requestbin-create \n",
    "os.environ['REQUESTBIN_URL'] = rburl[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a URL to recieve webhooks from our job, Let's look at our job request. The way this job is configured, it will send the requestbin notifications for every job event until the job reaches a terminal state. For a full list of job events, please see http://docs.agaveplatform.org/#job-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"job.txt\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"echo hello\"\n",
    "   }\n",
    " }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the setvar() command can evalute `$()` style bash shell substitutions, we will use it to submit our job. This will capture the output of the submit command, and allow us to parse it for the JOB_ID. We'll use the JOB_ID in several subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F job.txt)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Monitoring and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, the requestbin you registered will receive webhooks from Agave every time a job event occurs. To monitor this in real time, evaluate the next cell an visit the printed url in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('%s?inspect'%os.environ['REQUESTBIN_URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also monitor the job status by polling. Note that the notifications you receive via email and webhook are less wasteful of resources. However, we show you this for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(20):\n",
    "    setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "    stat = os.environ[\"STAT\"]\n",
    "    sleep(5.0)\n",
    "    if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs-history command provides you a record of the steps of what your job did. If your job fails for some reason, this is your best diagnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-history ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command shows you the job id's and status of the last 5 jobs you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-list -l 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next command provides you with a list of all the files generated by your job. You can use it to figure out which files you want to retrieve with jobs-output-get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-output-list --rich --filter=type,length,name ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.out\n",
    "!cat fork-command-1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard error output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.err\n",
    "!cat fork-command-1.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Automating</h3>\n",
    "Because we're working in Python, we can simply glue the above steps together and create a script to run jobs for us and fetch the standard output. Let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile runagavecmd.py\n",
    "from setvar import *\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def runagavecmd(cmd,infile=None):\n",
    "    setvar(\"REMOTE_COMMAND=\"+cmd)\n",
    "    setvar(\"REQUESTBIN_URL=$(requestbin-create)\")\n",
    "    print(\"\")\n",
    "    print(\" ** QUERY STRING FOR REQUESTBIN **\")\n",
    "    print('%s?inspect'%os.environ['REQUESTBIN_URL'])\n",
    "    print(\"\")\n",
    "    # The input file is an optional parameter, both\n",
    "    # to our function and to the Agave application.\n",
    "    if infile == None:\n",
    "        setvar(\"INPUTS={}\")\n",
    "    else:\n",
    "        setvar('INPUTS={\"datafile\":\"'+infile+'\"}')\n",
    "    setvar(\"JOB_FILE=job-remote-$PID.txt\")\n",
    "    # Create the Json for the job file.\n",
    "    writefile(\"$JOB_FILE\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"${REMOTE_COMMAND}\"\n",
    "   },\n",
    "   \"inputs\":${INPUTS}\n",
    " }\"\"\")\n",
    "    # Run the job and capture the output.\n",
    "    setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F $JOB_FILE)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")\n",
    "    if not re.match(r'^[\\w-]+$',os.environ['JOB_ID']):\n",
    "        print(\"Bad JOB_ID:\",os.environ['JOB_ID'])\n",
    "        return\n",
    "    # Poll and wait for the job to finish.\n",
    "    for iter in range(80): # Excessively generous\n",
    "        setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "        stat = os.environ[\"STAT\"]\n",
    "        sleep(5.0)\n",
    "        if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "            break\n",
    "    # Fetch the job output from the remote machine\n",
    "    setvar(\"CMD=jobs-output-get ${JOB_ID} fork-command-1.out\")\n",
    "    os.system(os.environ[\"CMD\"])\n",
    "    print(\"All done! Output follows.\")\n",
    "    # Load the output into memory\n",
    "    output=readfile(\"fork-command-1.out\")\n",
    "    print(\"=\" * 70)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runagavecmd as r\n",
    "import imp\n",
    "imp.reload(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.runagavecmd(\"lscpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Permissions and Sharing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the users and the permssions they have to look at the given job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-pems-list ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pair off with your neighbor and both of you share your job with them.\n",
    "# For now, just give read access\n",
    "!jobs-pems-update -u training002 -p READ ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if we can see our neighbor's job\n",
    "# Now let's see if we can see our neighbor's job\n",
    "shared_job = !jobs-search --filter=id -l 1 owner.neq=${AGAVE_USERNAME} \n",
    "os.environ['SHARED_JOB_ID'] = shared_job[0]\n",
    "print(os.environ['SHARED_JOB_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permissions are just that, permitting someone to do something. You said your neighbor could view your job. Let's see what that means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You already searched for the job and found it, so you should be able to lis\n",
    "# an view the details\n",
    "!jobs-list $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should also be able to view the history. Here we'll just return the last few \n",
    "# events. Notice the history event showed up history event\n",
    "!jobs-history --limit 3 --order desc $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also view their job output\n",
    "!jobs-output-list -L $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we no longer want to see the job. Let's delete it.\n",
    "!jobs-delete $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doah! We can't delete the shared job because we weren't granted write permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grant write access and see what we can do\n",
    "!jobs-pems-update -u training002 -p READ_WRITE ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if we can delete the shared job\n",
    "!jobs-delete $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait, now we don't have anything to work with. \n",
    "# No worries. Agave doens't really delete anything. Your job is still there\n",
    "# We just need to restore it.\n",
    "!jobs-restore $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to rerun the job\n",
    "!jobs-resubmit $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, what app did they use in the job?\n",
    "\n",
    "shared_job = !jobs-list -v --filter=executionSystem,appId $SHARED_JOB_ID | jq -r '. | [ .executionSystem , .appId] | .[]'\n",
    "print(shared_job)\n",
    "os.environ['SHARED_JOB_APP'] = shared_job[1]\n",
    "os.environ['SHARED_JOB_SYSTEM'] = shared_job[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh, we don't have permission to even view the app. Guess our job permissions\n",
    "# don't extend to the application. Let's be a good neighbor and share our apps\n",
    "# with each other\n",
    "! apps-pems-update -u training002 -p READ \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score, but wait, do I need execute to run? We should granb that too.\n",
    "# Hmm, do we have access to the app?\n",
    "! apps-pems-update -u training002 -p EXECUTE \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess permissions aren't hierachical. Now i can execute it (I think), but I can't\n",
    "# read it. How aabout we grant read_execute instead\n",
    "! apps-pems-update -u training002 -p READ_EXECUTE \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we can rerun our neighbor's job, right\n",
    "!jobs-resubmit -v $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drat. why can't we run now? Do we have system access?\n",
    "!systems-roles-list $SHARED_JOB_SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, let's skip to the end. we'll just realize we should grant a user rather than guest role\n",
    "# to the system\n",
    "!systems-roles-addupdate -u training002 -r USER $AGAVE_EXECUTION_SYSTEM_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that should work, right?\n",
    "!systems-roles-list $SHARED_JOB_SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So can we run the job now?\n",
    "resubmitted_job_id = ! jobs-resubmit -v --filter=id $SHARED_JOB_ID | jq -r '.id'\n",
    "os.environ['RESUBMITTED_JOB_ID'] = resubmitted_job_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yay. wait, who owns the data?\n",
    "print (resubmitted_job_id[0])\n",
    "! jobs-pems-list $RESUBMITTED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine\n",
    "# kill it, we're moving on.\n",
    "! jobs-stop $RESUBMITTED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also share data a few ways\n",
    "job_output_url = ! jobs-output-list -v --filter=_links $JOB_ID fork-command-1.out | jq -r '.[0]._links.self.href'\n",
    "os.environ['JOB_OUTPUT_URL'] = job_output_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postit_url = ! postits-create -m 3 -l 86400 -V $JOB_OUTPUT_URL | jq -r '.result._links.self.href' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the link a few times to see it working.\n",
    "print (postit_url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you can also share your data via the files api\n",
    "# let's share the job directory with each other\n",
    "job_path = ! jobs-list -v $JOB_ID | jq -r '.outputPath'\n",
    "os.environ['JOB_OUTPUT_FOLDER_PATH'] = job_path[0]\n",
    "! files-pems-update -u training002 -p read -S $AGAVE_EXECUTION_SYSTEM_ID $JOB_OUTPUT_FOLDER_PATH/fork-command-1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobs-delete $JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Data\n",
    "\n",
    "You can also use Agave to manage your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Metadata & Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agave provides two different ways to create and manage custom metadata and realationships between your resources. The Metadata API provides a searchable key-value store that supports structured as well as binary data. Let's see how this works by adding some metadata about our app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-app-metadata.json'\n",
      "APP_METADATA_ID=4199900087058895336-242ac11d-0001-012\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-app-metadata.json\", \"\"\"\n",
    "{\n",
    "  \"name\": \"notes\",\n",
    "  \"value\": [\n",
    "      \"Taking first steps with the Agave Platform CLI. This is pretty cool.\"\n",
    "  ]\n",
    "}\n",
    "\"\"\")\n",
    "setvar(\"\"\"\n",
    "APP_METADATA_ID=$(metadata-addupdate -v -F fork-app-metadata.json | jq -r '.uuid')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tags API works similar to the metadata, but enforces a unique per-user namespace on the tag names. Tagging is an option API, and as such, is not enabled for new API clients by default in every tenant. \n",
    "\n",
    "> You can subscribe to this and other boutique APIs by running the folling command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apps\n",
      "Files\n",
      "Jobs\n",
      "Meta\n",
      "Monitors\n",
      "Notifications\n",
      "Postits\n",
      "Profiles\n",
      "Systems\n",
      "Transforms\n",
      "tenant: sandbox\n",
      "username: dooley\n",
      "time left: 14377 seconds\n",
      "expires at: Sat Jul 21 22:26:25 UTC 2018\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# echo $AGAVE_APP_NAME\n",
    "# clients-list \n",
    "\n",
    "# for i in tags uuids tenants; \n",
    "# do \n",
    "#     echo \"clients-subscriptions-update -V -N $i $AGAVE_APP_NAME\"\n",
    "#     clients-subscriptions-update -V -N $i \"$AGAVE_APP_NAME\"\n",
    "# done\n",
    "\n",
    "clients-subscriptions-list --limit=50 \"$AGAVE_APP_NAME\"\n",
    "auth-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your current token will not have access to these newly subscribed APIs, so we need to \n",
    "revoke our current token and get a fresh one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mToken 4fb3e5ad3c469263039c4d78af7cca7 successfully revoked\u001b[0m\n",
      "\u001b[1;0mToken for sandbox:dooley successfully refreshed and cached for 14400 seconds\n",
      "9632189215d348e4ba1cb48c9785f6ab\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!auth-tokens-revoke\n",
    "!auth-tokens-create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tags-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events and Notificaitons \n",
    "\n",
    "Earlier we saw how we could subscribe for webhook job status updates to be sent to a RequestBin. Job status updates are one of the many events Agave throws. Other examples are file updates, metadata creation, user creation, system outages. \n",
    "\n",
    "> You can see the current list of subscribable events broken down by resource in the [Agave Platform Event Reference](https://docs.agaveplatform.org/#event-reference) section of the [Agave Developer Docs](https://docs.agaveplatform.org/).\n",
    "\n",
    "That is one of several delivery methods supported by Agave. Agave also supports:  \n",
    "\n",
    "* Slack \n",
    "* Email \n",
    "* Websocket\n",
    "* HTTP GET/POST\n",
    "* Event triggers\n",
    "* Internal URL\n",
    "* Persistent queues\n",
    "\n",
    "We will look at some of these later on when we talk about automation and publishing. Right now, let's look at some examples with our current examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent vs transient notifications\n",
    "\n",
    "When you create a notification, you can subscribe to the first occurrence of an event or to every even on a resources. Our previous jobs used persistent subscriptions. One notification subscription was created with the job, a wildcard, `*` was used as the named event, meaning \"subscribe this requestbin to notifications for any event thrown by this job,\" and `persistent` was set to true, meaning that the subscription will stay active regardless of how often it fires. \n",
    "\n",
    "If we did not want to get quite so many notifications sent to us, we could create one notifications for each individual event that we care about. The following is a job that illustrates several different notification types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `job-with-many-notifications.txt'\n"
     ]
    }
   ],
   "source": [
    "# !echo $AGAVE_EXECUTION_SYSTEM_ID\n",
    "# writefile(\"$HOME/work/job-with-many-notifications-exe.txt\",\"\"\"\n",
    "# #!/usr/bin/env bash\n",
    "# ]echo \"Inside job \\${AGAVE_JOB_ID}\n",
    "\n",
    "# # Make runtime callback event to write a metadata item \n",
    "# # from inside the job.\n",
    "# \\${AGAVE_JOB_CALLBACK_NOTIFICATION|JOB_METADATA_EVENT|name:JOB_NAME,value:JOB_APP_ID,associatedUuid:JOB_ID}\n",
    "# \"inputs\": {\n",
    "#        \"datafile\": \"agave://$AGAVE_EXECUTION_SYSTEM_ID/work/job-with-many-notifications-exe.txt\"\n",
    "#    },\n",
    "# ,\n",
    "#     {\n",
    "#       \"url\": \"$(auth-check -v | jq -r '.baseurl')/meta/v2/data\",\n",
    "#       \"event\": \"JOB_METADATA_EVENT\",\n",
    "#       \"persistent\":\"false\",\n",
    "#       \"policy\": {\n",
    "#          \"retryStrategy\": \"DELAYED\",\n",
    "#          \"retryLimit\": 2,\n",
    "#          \"retryRate\": 5,\n",
    "#          \"retryDelay\": 10,\n",
    "#          \"saveOnFailure\": true\n",
    "#        }\n",
    "#     }\n",
    "# \"\"\")\n",
    "\n",
    "writefile(\"job-with-many-notifications.txt\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${SLACK_WEBHOOK_URL}\",\n",
    "      \"event\":\"RUNNING\",\n",
    "      \"persistent\": false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"${SLACK_WEBHOOK_URL}\",\n",
    "      \"event\":\"FINISHED\",\n",
    "      \"persistent\": false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&owner=\\${OWNER}&id=\\${JOB_ID}\",\n",
    "      \"event\":\"CLEANING_UP\",\n",
    "      \"persistent\": false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"demo+spam@agaveplatform.org\",\n",
    "      \"event\":\"CLEANING_UP\",\n",
    "      \"persistent\": false\n",
    "    },\n",
    "    {\n",
    "      \"url\":\"https://httpbin.org/500\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\",\n",
    "      \"policy\": {\n",
    "         \"retryStrategy\": \"NONE\",\n",
    "         \"saveOnFailure\": true\n",
    "       }\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"date && echo hello\"\n",
    "   }\n",
    " }\n",
    "\"\"\")\n",
    "\n",
    "# setvar(\"\"\"\n",
    "# # Capture the output of the job submit command\n",
    "# OUTPUT=$(jobs-submit -W -F job-with-many-notifications.json)\n",
    "# # Parse out the job id from the output\n",
    "# JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT=Successfully submitted job 803280584174726680-242ac114-0001-007\n",
      "JOB_ID=803280584174726680-242ac114-0001-007\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=FINISHED\n",
      "\u001b[1;0mJob accepted and queued for submission.\n",
      "Skipping staging. No input data associated with this job.\n",
      "Preparing job for submission.\n",
      "Attempt 1 to submit job\n",
      "Fetching app assets from agave://sandbox-storage-dooley/agave-deploy\n",
      "Staging runtime assets to agave://sandbox-exec-dooley//home/jovyan/dooley/job-803280584174726680-242ac114-0001-007-fork-command-1\n",
      "CLI job successfully forked as process id 6535\n",
      "CLI job successfully forked as process id 6535\n",
      "Job receieved duplicate RUNNING notification\n",
      "Job completed execution\n",
      "Job completed. Skipping archiving at user request.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F job-with-many-notifications.txt)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")\n",
    "for iter in range(20):\n",
    "    setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "    stat = os.environ[\"STAT\"]\n",
    "    sleep(5.0)\n",
    "    if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "        break\n",
    "!jobs-history $JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m| name                  | length | permission | type | lastModified           |\r\n",
      "| ----                  | ------ | ---------- | ---- | ------------           |\r\n",
      "| .agave.archive        | 78     | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| .agave.log            | 395    | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| fork-command-1.err    | 0      | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| fork-command-1.ipcexe | 2499   | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| fork-command-1.out    | 35     | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| fork-command-1.pid    | 5      | READ_WRITE | file | Jul 21, 2018   8:17 pm |\r\n",
      "| fork-test.txt         | 29     | READ_WRITE | file | Jul 21, 2018   7:33 pm |\r\n",
      "| fork-wrapper.txt      | 22     | READ_WRITE | file | Jul 21, 2018   7:33 pm |\r\n",
      "| input.txt             | 1753   | READ_WRITE | file | Jul 21, 2018  12:41 am |\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-list --rich $JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 22 01:17:47 UTC 2018\r\n",
      "hello\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get -P $JOB_ID fork-command-1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this job runs, you will see notifications sent to:\n",
    "\n",
    "* The `#training-webhooks` channel on the [Agave Platform Slack Team](https://slackin.agaveplatform.org) when the job starts running and enters a finished state.  \n",
    "* Your RequestBin when the job's compute process exits and Agave starts the cleanup phase of the job lifecycle.  \n",
    "* An email to a autoresponder email account.  \n",
    "\n",
    "The last two notifications aren't quite as straight forward. The first one will send a message to `httpbin`, a http mirror service that allows you to craft URL that return predetermined content. The `https://httpbin.org/500` we subscribe to the wildcard job event will always return a [500 error code], signaling a failed delivery. We use this example to show a retry attempt policy. The `policy` object of this notifiation says to quit after the first attempt without any subsequent retires and immediately store the failed notification attempt information in the dead letter queue for the notification where it can be queried later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://requestbin.agaveapi.co/1880ovh1?inspect\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"${REQUESTBIN_URL}?inspect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid value for event.\n",
      "stty: 'standard input': Inappropriate ioctl for device\n",
      "\n",
      "Please specify a valid notification object id to query for failures\n",
      "stty: 'standard input': Inappropriate ioctl for device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "HTTPBIN_JOB_NOTIFICATION_ID=$(notifications-search -l 1 -v associatedUuid=$JOB_ID url=https://httpbin.org/500 | jq -r '.id')\n",
    "notifications-list-failures $HTTPBIN_JOB_NOTIFICATION_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs are not the only things that throw or receive job events. Perhaps we want to track the number of times our app, or any app is run on a system. We can subscribe for an event every time a job is run on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setvar(\"\"\"\n",
    "AGAVE_EXECUTION_SYSTEM_UUID=$(systems-list --filter=uuid -v $AGAVE_EXECUTION_SYSTEM_ID | jq '.uuid')\n",
    "\"\"\")\n",
    "\n",
    "writefile(\"system-job-notification.json\", \"\"\"\n",
    "{\n",
    "  \"url\":\"https://httpbin.org/500\",\n",
    "  \"event\":\"JOB_SUBMIT\",\n",
    "  \"persistent\":\"true\",\n",
    "  \"associatedUuid\": \"$AGAVE_EXECUTION_SYSTEM_UUID\",   \n",
    "  \"policy\": {\n",
    "     \"retryStrategy\": \"NONE\",\n",
    "     \"retryLimit\": 2,\n",
    "     \"retryRate\": 1,\n",
    "     \"retryDelay\": 0,\n",
    "     \"saveOnFailure\": true\n",
    "   }\n",
    "}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agave can watch for events on data it touches directly and indirectly. Here we subscribe to notifications on changes to a specific file, our app wrapper template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setvar(\"\"\"\n",
    "FILE_ITEM_UUID=$(files-list --filter=* -v -S AGAVE_STORAGE_SYSTEM_ID $AGAVE_APP_DEPLOYMENT_PATH/fork-wrapper.txt | jq '.uuid')\n",
    "\"\"\")\n",
    "\n",
    "writefile(\"file-overwritten-notification.json\", \"\"\"\n",
    "{\n",
    "  \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&path=\\${PATH}\",\n",
    "  \"event\":\"OVERWRITTEN\",\n",
    "  \"persistent\":\"false\",\n",
    "  \"associatedUuid\": \"${FILE_ITEM_UUID}\"\n",
    "}\n",
    "\"\"\")\n",
    "fileOverwriteNotification = !notifications-addupdate -v -F file-overwritten-notification.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subscribe to changes to our app deployment directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setvar(\"\"\"\n",
    "DEPLOYMENT_DIRECTORY_UUID=$(files-list -l 1 --filter=* -v -S AGAVE_STORAGE_SYSTEM_ID $AGAVE_APP_DEPLOYMENT_PATH | jq '.[0].uuid')\n",
    "\"\"\")\n",
    "\n",
    "writefile(\"directory-content-changed-notification.json\", \"\"\"\n",
    "{\n",
    "  \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&path=\\${PATH}\",\n",
    "  \"event\":\"CONTENT_CHANGED\",\n",
    "  \"persistent\":\"false\",\n",
    "  \"associatedUuid\": \"${DEPLOYMENT_DIRECTORY_UUID}\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "directoryChangeNotification = !notifications-addupdate -v -F directory-content-changed-notification.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload our job wrapper template to our app's deployment directory again and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ${REQUESTBIN_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and create these notification subscriptions by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's upload a file and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('%s?inspect'%os.environ['REQUESTBIN_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Agave ToGo web portal  \n",
    "\n",
    "Follow the link below to run your job from a web portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo http://togo.agaveplatform.org/app/#/apps/${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
