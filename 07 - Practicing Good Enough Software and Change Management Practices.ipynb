{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Good Enough Software and Change Management Practices\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/agave\n",
      "AGAVE_APP_DEPLOYMENT_PATH=agave-deploy\n",
      "AGAVE_APP_NAME=training-dooley\n",
      "AGAVE_EXECUTION_SYSTEM_ID=sandbox-exec-dooley\n",
      "AGAVE_STORAGE_HOME_DIR=/home/jovyan\n",
      "AGAVE_STORAGE_SYSTEM_ID=sandbox-storage-dooley\n",
      "AGAVE_STORAGE_WORK_DIR=/home/jovyan\n",
      "AGAVE_SYSTEM_SITE_DOMAIN=localdomain\n",
      "CMD=jobs-output-get 4347833118371933720-242ac114-0001-007 fork-command-1.out\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-5058.txt\n",
      "JOB_ID=Invalid Credentials\n",
      "/bin/sh: 2: stty:: not found\n",
      "MACHINE_NAME=sandbox\n",
      "MACHINE_USERNAME=jovyan\n",
      "OUTPUT=Invalid Credentials\n",
      "stty: 'standard input': Inappropriate ioctl for device\n",
      "PBTOK=\n",
      "REMOTE_COMMAND=ls /usr/install\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/1or1rh91\n",
      "SCRATCH_DIR=/home/jovyan\n",
      "STAT=Invalid Credentials\n",
      "stty: 'standard input': Inappropriate ioctl for device\n",
      "\n",
      "/bin/sh: 2: /bin/sh:: not found\n",
      "VM_IPADDRESS=52.15.62.13\n",
      "\u001b[1;0mToken for sandbox:dooley successfully refreshed and cached for 14400 seconds\n",
      "f07b3ea320341d27334e602b13f61473\u001b[0m\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/agave\n",
    "\n",
    "%cd ~/agave\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from setvar import *\n",
    "from time import sleep\n",
    "\n",
    "loadvar()\n",
    "!auth-tokens-refresh || auth-tokens-create\n",
    "\n",
    "import runagavecmd as r # created in notebook \"05 - Hands on with The Agave CLI.ipynb\"\n",
    "import imp\n",
    "imp.reload(r)\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software  \n",
    "\n",
    "\n",
    "\n",
    "> Place a brief explanatory comment at the start of every program  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous notebook walked us through the process of building and testing the FUNWAVE-TVD app a couple different ways. We can take a further step towards improving the user experience by including a static test dataset with the source code so every user can run the exact same build, test, and validation commands with confidence that the results they got were the ones they should get. This lines up favorably with the Good Enough recommendation to:  \n",
    "\n",
    "> Provide a simple example or test data set\n",
    "\n",
    "Let's take a moment to add the `input.txt` file we used in our previous runs to the application repository on our sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created folder data\n",
      "Successfully copied ./input.txt to FUNWAVE-TVD/data/input.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "files-mkdir -N \"data\" -S $AGAVE_STORAGE_SYSTEM_ID   ./FUNWAVE-TVD\n",
    "files-copy -D \"FUNWAVE-TVD/data/input.txt\"  -S $AGAVE_STORAGE_SYSTEM_ID  ./input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add it to our Agave app deployment directory so we can be assured that it is available whenever the application is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied ./input.txt to agave-deploy/input.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "files-copy -D \"$AGAVE_APP_DEPLOYMENT_PATH/input.txt\"  -S $AGAVE_STORAGE_SYSTEM_ID ./input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a sample dataset, let's update our app definition to include the sample dataset as the default input. In doing so, we can guarantee that users have a predictable experience the first time they run our app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read old app definition\n",
    "appJson = json.load(open(\"fork-app.txt\"))\n",
    "\n",
    "# update the default value of our `datafile` input\n",
    "appJson['inputs'][0]['value']['default'] =\"agave://{}/{}/input.txt\".format(appJson['deploymentSystem'],appJson['deploymentPath'])\n",
    "\n",
    "# add some semantic info about the file\n",
    "appJson['inputs'][0]['semantics'] = {'ontology': [\"text\"]}\n",
    "\n",
    "# save the definition to a new file\n",
    "json.dump(appJson, open(\"fork-app-with-default-input.json\",\"w\"),indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new input defintion for our app now has the new default value and ontological information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"datafile\",\n",
      "  \"details\": {\n",
      "    \"label\": \"Data file\",\n",
      "    \"description\": \"\",\n",
      "    \"argument\": null,\n",
      "    \"showArgument\": false\n",
      "  },\n",
      "  \"value\": {\n",
      "    \"default\": \"agave://sandbox-storage-dooley/agave-deploy/input.txt\",\n",
      "    \"order\": 0,\n",
      "    \"required\": false,\n",
      "    \"validator\": \"\",\n",
      "    \"visible\": true\n",
      "  },\n",
      "  \"semantics\": {\n",
      "    \"ontology\": [\n",
      "      \"text\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(appJson['inputs'][0],indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point you will want to publish the results of your research. At that time, you will need to provide references to your data, code, and results. The Good Enough recommendation is to: \n",
    "\n",
    "> Submit code to a reputable DOI-issuing repository\n",
    "\n",
    "Ironically, we are using Github for this tutorial and they do not currently issue DOI. There are, however, plenty of other options, including a recommendation from the Github team itself.\n",
    "\n",
    "* Github wrote a blog about [Making Your Code Citeable](https://guides.github.com/activities/citable-code/) with a free DOI from [Zenodo](https://zenodo.org/) for your Github repository.  \n",
    "* [Figshare](https://figshare.org) provides DOI for any data hosted there. \n",
    "* [The Journal of Open Source Software](https://joss.org) provides free publishing and DOI for software documented and published in their journal in the form of a short paper.\n",
    "* [DataCite](https://datacite.org) Provides search, discovery, and DOI for published data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the easiest ways to get started with these services is to add a [CodeMeta](https://codemeta.github.io/) file to your project so it can be discovered in ways that span languages, publishing services, and dependency system syntax. We included a sample codemeta file for our FUNWAVE-TVD application to this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file `../notebooks/etc/codemeta.json'\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/codemeta/codemeta/master/codemeta.jsonld\",\n",
      "  \"@type\": \"SoftwareSourceCode\",\n",
      "  \"identifier\": \"FUNWAVE-TVD\",\n",
      "  \"description\": \"FUNWAVEâ€“TVD is the TVD version of the fully nonlinear Boussinesq wave model (FUNWAVE) initially developed by Kirby et al. (1998)\",\n",
      "  \"name\": \"FUNWAVE-TVD\",\n",
      "  \"codeRepository\": \"https://github.com/fengyanshi/FUNWAVE-TVD\",\n",
      "  \"issueTracker\": \"https://github.com/fengyanshi/FUNWAVE-TVD/issues\",\n",
      "  \"license\": \"https://opensource.org/licenses/BSD-2-Clause\",\n",
      "  \"version\": \"3.3\",\n",
      "  \"programmingLanguage\": {\n",
      "    \"@type\": \"ComputerLanguage\",\n",
      "    \"name\": \"Fortrain\",\n",
      "    \"version\": \"77\",\n",
      "    \"url\": \"https://gcc.gnu.org/fortran/\"\n",
      "  },\n",
      "  \"runtimePlatform\": \"GNU Fortran 77\",\n",
      "  \"author\": [\n",
      "    {\n",
      "      \"@type\": \"Person\",\n",
      "      \"givenName\": \"Fengyan\",\n",
      "      \"familyName\": \"Shi\",\n",
      "      \"email\": \"fyshi@udel.edu\",\n",
      "      \"@id\": \"https://orcid.org/0000-0003-1568-2449\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"Person\",\n",
      "      \"givenName\": \"James\",\n",
      "      \"familyName\": \"Kirby\",\n",
      "      \"email\": \"kirby@udel.edu\",\n",
      "      \"@id\": \"https://orcid.org/0000-0001-6978-899X\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"Person\",\n",
      "      \"givenName\": \"Babak\",\n",
      "      \"familyName\": \"Tehranirad\",\n",
      "      \"email\": \"btrad@udel.edu\",\n",
      "      \"@id\": \"https://orcid.org/0000-0002-1634-9165\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"Person\",\n",
      "      \"givenName\": \"Jeffrey\",\n",
      "      \"familyName\": \"Harris\",\n",
      "      \"email\": \"\",\n",
      "      \"@id\": \"https://orcid.org/0000-0002-8167-7974\"\n",
      "    }\n",
      "  ],\n",
      "  \"copyrightHolder\": [\n",
      "    {\n",
      "      \"@id\": \"http://www.udel.edu/kirby/programs/funwave/funwave.html\",\n",
      "      \"@type\": \"Organization\",\n",
      "      \"name\": \"FUNWAVE Development Team\",\n",
      "      \"url\": \"http://www.udel.edu/kirby/programs/funwave/funwave.html\"\n",
      "    }\n",
      "  ],\n",
      "  \"maintainer\": {\n",
      "    \"@type\": \"Person\",\n",
      "    \"givenName\": \"Fengyan\",\n",
      "    \"familyName\": \"Shi\",\n",
      "    \"email\": \" fyshi@udel.edu\",\n",
      "    \"@id\": \"https://orcid.org/0000-0003-1568-2449\"\n",
      "  },\n",
      "  \"softwareSuggestions\": [\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"Open MPI\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://www.open-mpi.org/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"Open MPI: Open Source High Performance Computing\",\n",
      "        \"url\": \"https://www.open-mpi.org/software/ompi/v2.1/\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"gfortran\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://gcc.gnu.org/fortran/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"GNU Fortran\",\n",
      "        \"url\": \"https://gcc.gnu.org/fortran/\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"gcc\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://gcc.gnu.org/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"GNU Compiler Collection (GCC)\",\n",
      "        \"url\": \"https://gcc.gnu.org/\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"softwareRequirements\": [\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"Open MPI\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://www.open-mpi.org/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"Open MPI: Open Source High Performance Computing\",\n",
      "        \"url\": \"https://www.open-mpi.org/software/ompi/v2.1/\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"gfortran\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://gcc.gnu.org/fortran/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"GNU Fortran\",\n",
      "        \"url\": \"https://gcc.gnu.org/fortran/\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"SoftwareApplication\",\n",
      "      \"name\": \"gcc\",\n",
      "      \"provider\": {\n",
      "        \"@id\": \"https://gcc.gnu.org/\",\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"GNU Compiler Collection (GCC)\",\n",
      "        \"url\": \"https://gcc.gnu.org/\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"contIntegration\": \"https://travis-ci.org/codemeta/codemetar\",\n",
      "  \"developmentStatus\": \"http://www.repostatus.org/#active\",\n",
      "  \"keywords\": [\n",
      "    \"wave simulation\",\n",
      "    \"mpi\",\n",
      "    \"coastal\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(readfile(\"../notebooks/etc/codemeta.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly looking at the format, you will notice that it's JSON and there is a good bit of linked data included. If you are familiar with Schema.org, you might recognize many of the fields as official types of one or more Schema.org definitions. This definition is in now way complete. We leave the addition of additional fields as an exercise. You can consult the [CodeMeta User Guide](https://codemeta.github.io/terms/) for a full list of terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [codemetar](https://ropensci.github.io/codemetar/) library for the R language provides several tools to help you author and validate CodeMeta files. Their validation tools is particularly helpful. Here is an example of its usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(codemetar) \n",
    "\n",
    "codemeta_validate(codemeta = \"../notebooks/etc/codemeta.json\", context=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload the `codemeta.json` file to our repository directory to include with our source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../notebooks/etc/codemeta.json...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "!files-upload --filetoupload=../notebooks/etc/codemeta.json  --systemid=$AGAVE_STORAGE_SYSTEM_ID  ./FUNWAVE-TVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping Track of Changes  \n",
    "\n",
    "Knowing how a piece of software changes over time can be challenging to do for invested iniviuals. For users, it can be downright intimidating, bordering on impossible. The Good Enough recommendation says to:  \n",
    "\n",
    "> Create, maintain, and use a checklist for saving and sharing changes to the project  \n",
    "\n",
    "One way to do that is by keeping a changelog. Changelogs are structued text documents that describe the major, an sometimes minor changes to a project over time an release. There are many way to stucture a changelog. For reasons we will quickly see, we recommend the format found at [keepachangelog.com](http://keepachangelog.com/). Their changelog format is a machine-parsable Markdown format which leverages semantic versioning. \n",
    "\n",
    "While we could generate the changelog by hand, for existing projects and active ones, this quickly becomes enough of a hassle to dissuade us from keeping up with. Luckily, we can leverage projects such as the [gitchangelog](https://github.com/vaab/gitchangelog) project to generate and maintain our changelog for us. The outcome will be a file named `CHANGELOG.md` that we can add and commit to our repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=cp .gitchangelog.rc /home/jovyan/FUNWAVE-TVD/.gitchangelog.rc && cd /home/jovyan/FUNWAVE-TVD && gitchangelog | tee CHANGELOG.md\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/1762h2g1\n",
      "\n",
      " ** QUERY STRING FOR REQUESTBIN **\n",
      "https://requestbin.agaveapi.co/1762h2g1?inspect\n",
      "\n",
      "INPUTS={\"datafile\":\"https://raw.githubusercontent.com/agavetraining/pearc18/master/etc/.gitchangelog.rc\"}\n",
      "JOB_FILE=job-remote-5058.txt\n",
      "Writing file `job-remote-5058.txt'\n",
      "OUTPUT=Successfully submitted job 4347833118371933720-242ac114-0001-007\n",
      "JOB_ID=4347833118371933720-242ac114-0001-007\n",
      "STAT=PENDING\n",
      "STAT=PROCESSING_INPUTS\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 4347833118371933720-242ac114-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "# Changelog\n",
      "\n",
      "\n",
      "## (unreleased)\n",
      "\n",
      "### Other\n",
      "\n",
      "* Added Onyx makefiles for sediment and vessel-sediment. [matt.malej@gmail.com]\n",
      "\n",
      "* Block Dmass. [Fengyan Shi]\n",
      "\n",
      "* Edgecolor. [Fengyan Shi]\n",
      "\n",
      "* Update makefiles. [Fengyan Shi]\n",
      "\n",
      "* Remove output. [Fengyan Shi]\n",
      "\n",
      "* Add sediment cases. [Fengyan Shi]\n",
      "\n",
      "* Output unit of sediment concentration. [Fengyan Shi]\n",
      "\n",
      "* Output unit of sediment concentration. [Fengyan Shi]\n",
      "\n",
      "* Add vessel module in sediment. [Fengyan Shi]\n",
      "\n",
      "* Typo in serial code. [Fengyan Shi]\n",
      "\n",
      "* Option wavemaker current balance. [Fengyan Shi]\n",
      "\n",
      "* Make check mass conservation a general setting. [Fengyan Shi]\n",
      "\n",
      "* Change breakwaterabsorbcoef default to 10, which is consistent with the previous version. [Fengyan Shi]\n",
      "\n",
      "* Add breakwater strength. [Fengyan Shi]\n",
      "\n",
      "* Fix dxdy for check mass conservation. [Fengyan Shi]\n",
      "\n",
      "* Add Dmass. [Fengyan Shi]\n",
      "\n",
      "* Correct unit in plot. [Fengyan Shi]\n",
      "\n",
      "* Add two vessle morphology cases. [Fengyan Shi]\n",
      "\n",
      "* Bug in bedload. [Fengyan Shi]\n",
      "\n",
      "* Set min reference depth. [Fengyan Shi]\n",
      "\n",
      "* Ghost cells of bedload. [Fengyan Shi]\n",
      "\n",
      "* Parallel sediment. [Fengyan Shi]\n",
      "\n",
      "* Porosity. [Fengyan Shi]\n",
      "\n",
      "* Update morphology. [Fengyan Shi]\n",
      "\n",
      "* Modify morphology and difine mindepthpickup. [Fengyan Shi]\n",
      "\n",
      "* Use max for mindepth and mindepthfrc. [Fengyan Shi]\n",
      "\n",
      "* Bug line 103, J=1,Nloc, I=1,Mloc, should be Nloc-1, Mloc-1. [Fengyan Shi]\n",
      "\n",
      "* ABS(AG(:)/sumAG) [Fengyan Shi]\n",
      "\n",
      "* Manning. [Fengyan Shi]\n",
      "\n",
      "* Linear jump. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'sediment' [Fengyan Shi]\n",
      "\n",
      "* Change nothing but resave the file. [Fengyan Shi]\n",
      "\n",
      "* Add report number. [Fengyan Shi]\n",
      "\n",
      "* Standard io and sediment module. [Fengyan Shi]\n",
      "\n",
      "* Add MASKtmp and remove ETAtmp. [Fengyan Shi]\n",
      "\n",
      "* Add MASKtmp, ETAtmp for wetting and drying. [Fengyan Shi]\n",
      "\n",
      "* Separate sediment from wave. [Fengyan Shi]\n",
      "\n",
      "* Linear_jump pressure. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #24 from fengyanshi/random_pxpy. [fengyanshi]\n",
      "\n",
      "  correct ijsta definition for serial code\n",
      "\n",
      "* Correct ijsta definition for serial code. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #23 from fengyanshi/random_pxpy. [fengyanshi]\n",
      "\n",
      "  Random pxpy, add missing part in wavemaker, add CD_breakwater\n",
      "\n",
      "* Correct pxpy for CD_sponge. [Fengyan Shi]\n",
      "\n",
      "* Add missing part mentioned by YoungKwang. [Fengyan Shi]\n",
      "\n",
      "* Add and commit, forgot the first time update. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #22 from fengyanshi/random_pxpy. [fengyanshi]\n",
      "\n",
      "  Random pxpy\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct pxpy. [Fengyan Shi]\n",
      "\n",
      "* Correct bugs in calculating resistence. [Fengyan Shi]\n",
      "\n",
      "* Added read phase. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #21 from malej/master. [fengyanshi]\n",
      "\n",
      "  Makefile build script for Onyx under Intel PrgEnv\n",
      "\n",
      "* Makefile build script for Onyx under Intel PrgEnv. [matt.malej@gmail.com]\n",
      "\n",
      "* Correct error in Manning formula. [Fengyan Shi]\n",
      "\n",
      "* Add close(1) for wkdata2d. [Fengyan Shi]\n",
      "\n",
      "* Change 6 digit to 4 of wavedatatype. [Fengyan Shi]\n",
      "\n",
      "* Resaved. [Fengyan Shi]\n",
      "\n",
      "* Remove print in io.F. [Fengyan Shi]\n",
      "\n",
      "* Parallelize LEF_SOL. [Fengyan Shi]\n",
      "\n",
      "* Calc nu_break at ghostcell. [Fengyan Shi]\n",
      "\n",
      "* Dep_ser. [Fengyan Shi]\n",
      "\n",
      "* Add waterlevel to depthwavemaker. [Fengyan Shi]\n",
      "\n",
      "* Simple case for left bc wavemaker. [Fengyan Shi]\n",
      "\n",
      "* Left_bc_irr, equalenergy/equaldefreq period,jon1d and 2d. [Fengyan Shi]\n",
      "\n",
      "* Add left_bc_irr, affected : bc.f dispersion.F etauv_solver.F io.F main.F mod_global.F wavemaker.F. [Fengyan Shi]\n",
      "\n",
      "* Add left_bc_irr, affected : bc.f dispersion.F etauv_solver.F io.F main.F mod_global.F wavemaker.F. [Fengyan Shi]\n",
      "\n",
      "* Add meteo tsunami. [Fengyan Shi]\n",
      "\n",
      "* Comment out cpu appinity. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Added Matlab scripts for levee and rip_2d with comments. [malej]\n",
      "\n",
      "* Added solitary wave levee python script for plotting in simple_cases - levee_1d. [malej]\n",
      "\n",
      "* Added commented Matlab scripts for all simple_cases postprocessing. [malej]\n",
      "\n",
      "* Moved vessel plot scripts into postprocessing directory. [malej]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [malej]\n",
      "\n",
      "* Added Python postrprocessing scripts with plot for simple_cases. [malej]\n",
      "\n",
      "* Modify pbs. [Fengyan Shi]\n",
      "\n",
      "* Wave+vessel. [Fengyan Shi]\n",
      "\n",
      "* Add plot files for resonance and vorticity calculation. [Fengyan Shi]\n",
      "\n",
      "* Add rip 2d case. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Cleaned up levee_1d input file and set for 4 CPUs. [malej]\n",
      "\n",
      "* Fixed the FIELD_IO_TYPE print statment issue. [malej]\n",
      "\n",
      "* Made changes to executable since we will have on Mills funwave_mills/vessel/spherical execs. [malej]\n",
      "\n",
      "* Removed -DVESSEL flag from the gneneric Makefile-Mills. [malej]\n",
      "\n",
      "* Changed input.txt for surface_1D with appropriate titles and NPROC # [malej]\n",
      "\n",
      "* Modify vessel_00002. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Removed testing file for pushing from mills. [malej]\n",
      "\n",
      "* Testing pushing to origin on mills. [malej]\n",
      "\n",
      "* Modify resonance case. [Fengyan Shi]\n",
      "\n",
      "* Add pbs script. [Fengyan Shi]\n",
      "\n",
      "* Remove exe files. [Fengyan Shi]\n",
      "\n",
      "* Add harbor resonance. [Fengyan Shi]\n",
      "\n",
      "* Added Makefiles for Mills for spherical/cartesian/vessel. [malej]\n",
      "\n",
      "* [WIP] added simple_case for levee_1d for the workshop - input files and bathy, still need postprocessing script. [malej]\n",
      "\n",
      "* Fix parallel mode in coupling option. [Fengyan Shi]\n",
      "\n",
      "* Update simple cases. [Fengyan Shi]\n",
      "\n",
      "* Remove sample head. [Fengyan Shi]\n",
      "\n",
      "* Add vessel case2. [Fengyan Shi]\n",
      "\n",
      "* Merge babaks sediment into 3.1beta. [Fengyan Shi]\n",
      "\n",
      "* Change sponge term. [Fengyan Shi]\n",
      "\n",
      "* Add defined parallel. [Fengyan Shi]\n",
      "\n",
      "* Remove question for Choi. [Fengyan Shi]\n",
      "\n",
      "* Add waterlevel before depthx and depthy. [Fengyan Shi]\n",
      "\n",
      "* Choi fixed construction. [Fengyan Shi]\n",
      "\n",
      "* Some change. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #20 from mayhl/parallelFieldIO. [fengyanshi]\n",
      "\n",
      "  Binary Field Output in Parallel\n",
      "\n",
      "* Merge remote-tracking branch 'upstream/master' into parallelFieldIO. [mayhl]\n",
      "\n",
      "* Added support for lower case input in FIELD_IO_TYPE. [mayhl]\n",
      "\n",
      "* Moved code for outputing FIELD_IO_TYPE to LOG file. [mayhl]\n",
      "\n",
      "* Changed FIELD_TYPE_IO to FIELD_IO_TYPE. Added FIELD_IO_TYPE to LOG.TXT. [mayhl]\n",
      "\n",
      "* Completed removing .txt and .bin in FIELD_IO_TYPE. [mayhl]\n",
      "\n",
      "* [WIP] removed .txt and .bin in FIELD_TYPE_IO... need to continue Mike. [malej]\n",
      "\n",
      "* [WIP] cleaned up with dos2unix, fixed all Makefiles for new modules, made a fix in MPI_FILE_WRITE_ALL. [malej]\n",
      "\n",
      "* Removing temporary tesing repo access file test.txt for Matt. [malej]\n",
      "\n",
      "* Testing read write repo for Matt. [malej]\n",
      "\n",
      "* Added subroutine for binary parallel output. See issues for bug information. [mayhl]\n",
      "\n",
      "* Change .out file extension to .txt for ASCII output. [mayhl]\n",
      "\n",
      "* Moved contents of PutFile subroutine into new module 'mod_parallel_field_io.F' and renamed PutFileACSII. [mayhl]\n",
      "\n",
      "* Added new input parameter 'FIELD_IO_TYPE' [mayhl]\n",
      "\n",
      "* Replaced Makefile with a modified version of Makefile-funwaveRDE. [mayhl]\n",
      "\n",
      "* Makefile. [Fengyan Shi]\n",
      "\n",
      "* Shorten input. [Fengyan Shi]\n",
      "\n",
      "* Add case vessel. [Fengyan Shi]\n",
      "\n",
      "* Vessel name changed to 5 digits. [Fengyan Shi]\n",
      "\n",
      "* Replace mod_storm with mod_meteo. [Fengyan Shi]\n",
      "\n",
      "* Get back mod_storm.F. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #19 from malej/master. [fengyanshi]\n",
      "\n",
      "  added vessel and bathy_correction modules to to ERDC HPC (Topaz) Makefiles\n",
      "\n",
      "* Merge remote-tracking branch 'upstream/master' [malej]\n",
      "\n",
      "* Merge pull request #18 from stevenrbrandt/user_friendliness. [fengyanshi]\n",
      "\n",
      "  Make it easier for users to spot errors they made in compiling or running Funwave-TVD.\n",
      "\n",
      "* Make it easier for users to spot errors they made in compiling or running Funwave-TVD. [Steven R. Brandt]\n",
      "\n",
      "* Added vessel and bathy_correction modules to to ERDC HPC (Topaz) Makefiles. [malej]\n",
      "\n",
      "* Merge remote-tracking branch 'upstream/master' [malej]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/malej/FUNWAVE-TVD. [malej]\n",
      "\n",
      "* Added a Makefile for https://funwave.erdc.dren.mil server build. [Matt Malej]\n",
      "\n",
      "* Updating system-specific Makefile and for profiling with OpenSS. [Matt Malej]\n",
      "\n",
      "* Add module meteo and remove module storm. [Fengyan Shi]\n",
      "\n",
      "* Add storm module. [Fengyan Shi]\n",
      "\n",
      "* Add tohoku case. [Fengyan Shi]\n",
      "\n",
      "* Make mean larger. [Fengyan Shi]\n",
      "\n",
      "* Corrected dispersion.F which has a problem with ghost cells. [Fengyan Shi]\n",
      "\n",
      "* Make pxpy random. [Fengyan Shi]\n",
      "\n",
      "* Add 1d cases. [Fengyan Shi]\n",
      "\n",
      "* Results. [Fengyan Shi]\n",
      "\n",
      "* Obs. [Fengyan Shi]\n",
      "\n",
      "* Add breakwater input and plot. [Fengyan Shi]\n",
      "\n",
      "* Wider breakwater. [Fengyan Shi]\n",
      "\n",
      "* Add breakwater. [Fengyan Shi]\n",
      "\n",
      "* Add irr_30d. [Fengyan Shi]\n",
      "\n",
      "* Fix 90 degree bug. [Fengyan Shi]\n",
      "\n",
      "* Post. [Fengyan Shi]\n",
      "\n",
      "* Update. [Fengyan Shi]\n",
      "\n",
      "* Update. [Fengyan Shi]\n",
      "\n",
      "* Add reg_30deg. [Fengyan Shi]\n",
      "\n",
      "* 30 degrees. [Fengyan Shi]\n",
      "\n",
      "* Minor. [Fengyan Shi]\n",
      "\n",
      "* Tst. [Fengyan Shi]\n",
      "\n",
      "* Test. [Fengyan Shi]\n",
      "\n",
      "* Change breaking. [Fengyan Shi]\n",
      "\n",
      "* Test. [Fengyan Shi]\n",
      "\n",
      "* Modification. [Fengyan Shi]\n",
      "\n",
      "* Add postprocessing. [Fengyan Shi]\n",
      "\n",
      "* Periodic. [Fengyan Shi]\n",
      "\n",
      "* Issue of Ywidth in irr. [Fengyan Shi]\n",
      "\n",
      "* Do again. [Fengyan Shi]\n",
      "\n",
      "* Add inlet shoal case. [Fengyan Shi]\n",
      "\n",
      "* Change dir name. [Fengyan Shi]\n",
      "\n",
      "* Change examples to benchmarks. [Fengyan Shi]\n",
      "\n",
      "* Remove indent. [Fengyan Shi]\n",
      "\n",
      "* Add no_uv_file. [Fengyan Shi]\n",
      "\n",
      "* Add all default. [Fengyan Shi]\n",
      "\n",
      "* Add breakwater partial reflection. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Update README.md. [fengyanshi]\n",
      "\n",
      "* Create _config.yml. [fengyanshi]\n",
      "\n",
      "* Update README.md. [fengyanshi]\n",
      "\n",
      "* Changes associated with bathy_correction. [Fengyan Shi]\n",
      "\n",
      "* Initial code of bathy_correction. [Fengyan Shi]\n",
      "\n",
      "* Add an option to do equal space in the frequency domain. [Fengyan Shi]\n",
      "\n",
      "* Add equal energy option. [Fengyan Shi]\n",
      "\n",
      "* Add panel source. [Fengyan Shi]\n",
      "\n",
      "* Add panel source. [Fengyan Shi]\n",
      "\n",
      "* Remove pressure source if panel source is used. [Fengyan Shi]\n",
      "\n",
      "* Add source_panel. [Fengyan Shi]\n",
      "\n",
      "* First step adding green function source. [Fengyan Shi]\n",
      "\n",
      "* Resave. [Fengyan Shi]\n",
      "\n",
      "* Add viscosity type + dep-limited criteria. [Fengyan Shi]\n",
      "\n",
      "* Modified Kennedy breaker. [Fengyan Shi]\n",
      "\n",
      "* Change PQ_scheme to ELSE in order use HU and HV for eddy viscosity breaking. [Fengyan Shi]\n",
      "\n",
      "* Back to vis in wavemaker. [Fengyan Shi]\n",
      "\n",
      "* Add option fixed dt. [Fengyan Shi]\n",
      "\n",
      "* Remove breaking inside wavemaker. [Fengyan Shi]\n",
      "\n",
      "* Breaking from Jbeg, Jend, Ibeg, Iend, instead of Nghost+1 or such. [Fengyan Shi]\n",
      "\n",
      "* Nu_vis, include ghost cells. [Fengyan Shi]\n",
      "\n",
      "* Change E16.5 to E16.8 for stations. [Fengyan Shi]\n",
      "\n",
      "* Remove duplication of wavemaker_mass calculation. [Fengyan Shi]\n",
      "\n",
      "* Update manual, JONSWAP and TMA 1D. [Fengyan Shi]\n",
      "\n",
      "* 1) add JONSWAP 1D and 2D, 2) add TMA 1D, 3) modify periodic bc to include theta=0. [Fengyan Shi]\n",
      "\n",
      "* Add resistance and output. [Fengyan Shi]\n",
      "\n",
      "* Add out_nu. [Fengyan Shi]\n",
      "\n",
      "* Add Ertekin et al source. [Fengyan Shi]\n",
      "\n",
      "* Make longer char for for mglob, nglob for writting LOG.txt. [Fengyan Shi]\n",
      "\n",
      "* Change tend and tbegin calculation based on fortran 90/95 standard. [Fengyan Shi]\n",
      "\n",
      "* DX(1,1) and DY(1,1) for spherical version. [Fengyan Shi]\n",
      "\n",
      "* Remove prime charameter in comment lines. [Fengyan Shi]\n",
      "\n",
      "* Made vessel pressure gradient negative before source.F. [Fengyan Shi]\n",
      "\n",
      "* Compare. [Fengyan Shi]\n",
      "\n",
      "* Change to mac version. [Fengyan Shi]\n",
      "\n",
      "* Change matts Makefile to Makefile_matt. [Fengyan Shi]\n",
      "\n",
      "* Add pdf. [Fengyan Shi]\n",
      "\n",
      "* Change theta_input to theta_input/180*pi. [Fengyan Shi]\n",
      "\n",
      "* Add 3.0 tex file. [Fengyan Shi]\n",
      "\n",
      "* Add check existing stations_file. [Fengyan Shi]\n",
      "\n",
      "* Add check existing depth. [Fengyan Shi]\n",
      "\n",
      "* Remove DepthFormat, keep only one format for reading depth at ele. [Fengyan Shi]\n",
      "\n",
      "* Chois updates:1)corrected Freq(Fmax), 2) normal spreading 3) corrected Matts typo CRAY. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #15 from malej/master. [fengyanshi]\n",
      "\n",
      "  dos2unix clean up, Makefile update and added CHL TN\n",
      "\n",
      "* Updated berkhoff2d input and Makefile in src, pushed all *.F in src through dos2unix. [malej]\n",
      "\n",
      "* Added intro to FUNWAVE CHL Tech Note document. [malej]\n",
      "\n",
      "* Merge pull request #8 from malej/master. [fengyanshi]\n",
      "\n",
      "  cleaned up io.F, fluxes.F and added two Makefiles for Lightning\n",
      "\n",
      "* Cleaned up io.F fluxes.F w.r.t signature mismatch and Cray compiler issues, added two Makefiles for Lightning -- code checks out OK. [malej]\n",
      "\n",
      "* Merge pull request #7 from malej/master. [fengyanshi]\n",
      "\n",
      "  changing repo structure\n",
      "\n",
      "* Updated .gitignore and moved/removed source from main directory and put it in /src dir. [malej]\n",
      "\n",
      "* New structure for entire repo, added doc folder, added Dan Topa's report, added and cleaned up examples. [malej]\n",
      "\n",
      "* Merge pull request #5 from malej/master. [fengyanshi]\n",
      "\n",
      "  added Topaz intel & sgi Makefiles and changed SYSTEM call for RESULT â€¦\n",
      "\n",
      "* Added Topaz intel & sgi Makefiles and changed SYSTEM call for RESULT folder to work for INTEL compiler (#if defined (INTEL)) in io.F. [Matt Malej]\n",
      "\n",
      "* Add correction from Hmo to Hrms in the irregular wavemaker. Choi pointed out this correction was only performed for ABS TMA wavemaker. [Fengyan Shi]\n",
      "\n",
      "* Convert Hmo to Hrms suggested by Choi. [Fengyan Shi]\n",
      "\n",
      "* Initialize tmp_2d_1 and tmp_2d_2, and remove tmp_2d_3 and tmp_2d_4, memory leaking causes wrong CD_4_SPONGE value as both direct and friction sponge selected. [Fengyan Shi]\n",
      "\n",
      "* Initialize vessel module. [Fengyan Shi]\n",
      "\n",
      "* Add vessel forcing. [Fengyan Shi]\n",
      "\n",
      "* Add output vessel stuff. [Fengyan Shi]\n",
      "\n",
      "* Add call vessel. [Fengyan Shi]\n",
      "\n",
      "* Set multi options for eddy viscosity breaker, if not defined the previous one will be used. [Fengyan Shi]\n",
      "\n",
      "* Choi found the dynamic nu caused instabilities. I made a static formula with a transition from Cbrk1 to Cbrk2. [Fengyan Shi]\n",
      "\n",
      "* Add Ubar Vbar after Froude_cap. [Fengyan Shi]\n",
      "\n",
      "* Change nu in wavebreaker. [Fengyan Shi]\n",
      "\n",
      "* If turn off viscosity breaking it results in un-allocate age_breaking. [Fengyan Shi]\n",
      "\n",
      "* Add sperical ij station option. [Fengyan Shi]\n",
      "\n",
      "* Correct spherical part as did two days ago. [Fengyan Shi]\n",
      "\n",
      "* Correction. [Fengyan Shi]\n",
      "\n",
      "* Chois version but change subroutine names. [Fengyan Shi]\n",
      "\n",
      "* Copy choi s fluxes.F here. [Fengyan Shi]\n",
      "\n",
      "* Change fluxes.F to fluxes 2.1 version. [Fengyan Shi]\n",
      "\n",
      "* Remove filter.F. [Fengyan Shi]\n",
      "\n",
      "* Start choi. [Fengyan Shi]\n",
      "\n",
      "* Automatically create result folder. [Fengyan Shi]\n",
      "\n",
      "* Change check_exist to file_exist for nesting option. [Fengyan Shi]\n",
      "\n",
      "* This modification is for sperical code. After Chois modification on flux terms the spherical code should be corrected accordingly. I used the previoius statements for the sphereical code. [Fengyan Shi]\n",
      "\n",
      "* Modify DX() and DY() in wavemaker for spherical coordinate. Actually they are not used in spherical version but without this the code cannot be compiled. [Fengyan Shi]\n",
      "\n",
      "* Add call SPHERICAL_IJ_STATION option. [Fengyan Shi]\n",
      "\n",
      "* Add SPHERICAL_IJ_STATION for coupling purpose. [Fengyan Shi]\n",
      "\n",
      "* Add tbegin and tend. [Fengyan Shi]\n",
      "\n",
      "* Remove tbegin and tend. [Fengyan Shi]\n",
      "\n",
      "* Add an option to ignore big slopes. [Fengyan Shi]\n",
      "\n",
      "* Add an option to ignore big slopes. [Fengyan Shi]\n",
      "\n",
      "* Remove Yc redefinition. [Fengyan Shi]\n",
      "\n",
      "* Remove Yc redefinition. [Fengyan Shi]\n",
      "\n",
      "* Edit some description. [Fengyan Shi]\n",
      "\n",
      "* Add friction sponge independent to depth. [Fengyan Shi]\n",
      "\n",
      "* Calculate cd_4_sponge, remove the basic cd from this variable. [Fengyan Shi]\n",
      "\n",
      "* Remove cd in the call. [Fengyan Shi]\n",
      "\n",
      "* Allocate cd_4_sponge and add it in the call calculate_friction_sponge. [Fengyan Shi]\n",
      "\n",
      "* Add cd_4_sponge. [Fengyan Shi]\n",
      "\n",
      "* Remove deallocate Phase2D because it causes discontinuity at processor interface. [Fengyan Shi]\n",
      "\n",
      "* Update README.md. [fengyanshi]\n",
      "\n",
      "* Add omgn2D for Cm and Sm scheme. [Fengyan Shi]\n",
      "\n",
      "* Use Cm and Sm in sources. [Fengyan Shi]\n",
      "\n",
      "* Use Cm and Sm scheme for 2D spectrum. [Fengyan Shi]\n",
      "\n",
      "* Remove allocate cm and sm and allocate them in wavemaker.F. [Fengyan Shi]\n",
      "\n",
      "* Add exchange of mask in initialization. [Fengyan Shi]\n",
      "\n",
      "* Choi made a change that move ETA2sum to right after the IF statement. [Fengyan Shi]\n",
      "\n",
      "* Merge branch 'master' of https://github.com/fengyanshi/FUNWAVE-TVD. [Fengyan Shi]\n",
      "\n",
      "* Add waterlevel in dep_wk. [Fengyan Shi]\n",
      "\n",
      "* Add WaterLevel. [Fengyan Shi]\n",
      "\n",
      "* Add filter related. [Fengyan Shi]\n",
      "\n",
      "* Add filter in bc.F. [Fengyan Shi]\n",
      "\n",
      "* Copy from NEW_CODE. [Fengyan Shi]\n",
      "\n",
      "* Copy filter from NEW_CODE folder. [Fengyan Shi]\n",
      "\n",
      "* Add option of filtering. [Fengyan Shi]\n",
      "\n",
      "* Move filtering in misc.F. [Fengyan Shi]\n",
      "\n",
      "* Add filtering. [Fengyan Shi]\n",
      "\n",
      "* Add WaterLevel. [Fengyan Shi]\n",
      "\n",
      "* Add reading WaterLevel. [Fengyan Shi]\n",
      "\n",
      "* Add water level parameter WaterLevel. [Fengyan Shi]\n",
      "\n",
      "* Change ibeg iend to 1, m. [Fengyan Shi]\n",
      "\n",
      "* Move call preview_mean down. [Fengyan Shi]\n",
      "\n",
      "* Correct. [Fengyan Shi]\n",
      "\n",
      "* Correction. [Fengyan Shi]\n",
      "\n",
      "* Add icount_mean. [Fengyan Shi]\n",
      "\n",
      "* Remove output_mix. [Fengyan Shi]\n",
      "\n",
      "* Remove output_mix and call preview_mean inside mixing_stuff. [Fengyan Shi]\n",
      "\n",
      "* Separate preview and preview_mean. [Fengyan Shi]\n",
      "\n",
      "* Remove waveheightsig. [Fengyan Shi]\n",
      "\n",
      "* Merge choi waveheightsig to waveheight. [Fengyan Shi]\n",
      "\n",
      "* Remove DMIXING in main.F. [Fengyan Shi]\n",
      "\n",
      "* Remove DMIXING in mod_global.F. [Fengyan Shi]\n",
      "\n",
      "* Remove DMIXING in mixing.F. [Fengyan Shi]\n",
      "\n",
      "* Remove DMIXING in io.F and init.F. [Fengyan Shi]\n",
      "\n",
      "* Include ETAmean in calculating significant wave height. [Fengyan Shi]\n",
      "\n",
      "* Merge pull request #1 from fengyanshi/tvd_edit. [fengyanshi]\n",
      "\n",
      "  remove a line\n",
      "\n",
      "* Remove a line. [fengyanshi]\n",
      "\n",
      "* Create README.md. [fengyanshi]\n",
      "\n",
      "* Add date. [fengyanshi]\n",
      "\n",
      "* Add title. [fengyanshi]\n",
      "\n",
      "* First add to repository. [fengyanshi]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's run the gitchangelog utility on the repository\n",
    "r.runagavecmd('cp .gitchangelog.rc /home/jovyan/FUNWAVE-TVD/.gitchangelog.rc && ' + \n",
    "              'cd /home/jovyan/FUNWAVE-TVD && ' + \n",
    "              'gitchangelog | tee CHANGELOG.md', \n",
    "              \"https://raw.githubusercontent.com/agavetraining/pearc18/master/etc/.gitchangelog.rc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Good Enough software recommendation is:\n",
    "\n",
    "> Share changes frequently  \n",
    "\n",
    "Having a changelog is much more useful when it is up to date. Rather than counting on ourself and our colleagues to remember to rebuild it each time, let's set up a git hook to rerun `gitchangelog` and update our changelog whenever we merge our develop branch back into master. The following script should handle that for us. \n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "\n",
    "# post-checkout hook - looks for changes to source files and, if\n",
    "# found, generates a new changelog file from the commit history.\n",
    "\n",
    "# To install, copy to your project's .git/hooks folder, and \n",
    "# `chmod +x post-merge`\n",
    "\n",
    "function changed {\n",
    "  git diff --name-only HEAD@{2} HEAD | grep \"^$1\" > /dev/null 2>&1\n",
    "}\n",
    "\n",
    "gitchangelog \n",
    "```\n",
    "\n",
    "We can install the scrirpt on our sandbox by copying the script to the repository `.git/hooks` folder and assigning execute privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: maintain,: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "files-upload --filetoupload scripts/git_hooks/post-merge --systemid $STORAGE_SYSTEM  \"./FUNWAVE-TVD/.git/hooks\"\n",
    "ssh sandbox \"chmod +x FUNWAVE-TVD/.git/hooks/post-merge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Versioning  \n",
    "\n",
    "The Good Enough recommenation is to:  \n",
    "\n",
    "> Copy the entire project whenever a significant change has been made      \n",
    "\n",
    "If your entire project, including data, is under version control, they may be a bit of overkill when you can just as easily branch the repository, however, as we are seeing, in our overall digital R&D lifcycle, there are other considerations upstream from just managing the code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintaining your Agave app \n",
    "\n",
    "Keeping your Agave app in sync with the code it represents will help your users feel secure that what they think they will be running is what will actually be run. Aside from the standard revision increment that happens whenever you update your app definition, additional information can be added to better inform users of its activity, utility, and reliability. \n",
    "\n",
    "\n",
    "### Updating your app definition  \n",
    "\n",
    "The lowest hanging fruit is simply to update your app definition. If any ontological terms, descriptions, etc. have changed, the `app.json` file should be updated to reflect the latest information. We can automate this with the use of the same `git-merge` file we used to update our changelog. \n",
    "\n",
    "Adding the following code to the end of that file will result in our app being updated whenever we merge into our master branch. \n",
    "\n",
    "```bash\n",
    "...\n",
    "\n",
    "AGAVE_APP_DEPLOYMENT_SYSTEM=$(jq -r '.deploymentSystem' app.json)\n",
    "AGAVE_APP_DEPLOYMENT_PATH=$(jq -r '.deploymentPath' app.json)\n",
    "\n",
    "if changed 'app.json'; then\n",
    "  files-upload -F app.json -S $AGAVE_APP_DEPLOYMENT_SYSTEM $AGAVE_APP_DEPLOYMENT_PATH\n",
    "  apps-addupdate -F app.json\n",
    "fi $APP_ID  \n",
    "\n",
    "...\n",
    "\n",
    "```  \n",
    "\n",
    "\n",
    "### Updating your app metadata\n",
    "\n",
    "If you have an additional metadata such as a CodeMeta, yaml, or CWL file for your app, updating the app's metadata with any new or changed content should be done now. \n",
    "\n",
    "```bash\n",
    "...\n",
    "\n",
    "# Look up an existing codemeta file stored in the metadata API.\n",
    "function lookup_agave_codemeta_metadata_uuid {\n",
    "   metadata-list --query '{\"name\": \"codemeta\"}' -P 5547200605505711640-242ac117-0001-005  --filter=uuid -v | jq -r '.[] | .uuid' | grep -v \"null\" | head -n 1\n",
    "}\n",
    "\n",
    "\n",
    "AGAVE_APP_ID=$(jq -r '.name + \"-\" + .version' app.json)\n",
    "AGAVE_APP_UUID=$(apps-list -v --filter=uuid $agave_app_id | jq -r '.uuid')\n",
    "\n",
    "# Push the codemeta definition up to the server whenever this changes\n",
    "if changed 'codemeta.json'; then\n",
    "  files-upload -F codemeta.json -S $AGAVE_APP_DEPLOYMENT_SYSTEM $AGAVE_APP_DEPLOYMENT_PATH\n",
    "\n",
    "  # Lookup Agave metadata item for the codemeta definition if it exists\n",
    "  AGAVE_CODEMETA_METADATA_ID=$(lookup_agave_codemeta_metadata_uuid)\n",
    "\n",
    "  # Update the entry. If no entry exists, this creates one.\n",
    "  jq --arg app_uuid $AGAVE_APP_UUID '. | {\"name\": \"codemeta\", \"value\": ., \"associatedUuid\": $app_uuid}' | metadata-addupdate -F - $AGAVE_CODEMETA_METADATA_ID\n",
    "\n",
    "fi\n",
    "\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "### Mirroring your app tags\n",
    "\n",
    "The tags you assign to your app probably will not change very often, but in the event a new feature requires changes to existing tags, or a reorganization of tags, then those updates should be done now.  \n",
    "\n",
    "### Deprecating your old app(s)\n",
    "\n",
    "Some releases, such as rollbacks, yanked releases, and security patches may justify the deprecation or disabling of a previous app version. This is where it would be done.\n",
    "\n",
    "### (Re)running benchmarks\n",
    "\n",
    "Once your build, unit, and integration tests pass, your app and its data are updated, and your assets are publised to their new location, benchmark jobs can be run to measure application performance before and after the release.\n",
    "\n",
    "```bash\n",
    "...\n",
    "\n",
    "# Uncomment to kick off benchmark suites whenever on merge to master\n",
    "AGAVE_JOB_TEMPLATE=$(jobs-template --cache --allfields $AGAVE_APP_ID)\n",
    "BENCHMARK_MERGE_REV=$(date +%s)\n",
    "\n",
    "for i in `ls -d benchmarks`; do\n",
    "  BENCHMARK_DIR=\"agave://$AGAVE_APP_DEPLOYMENT_SYSTEM/$(pwd)/benchmarks/$i\"\n",
    "  BENCHMARK_JOB_NAME=\"benchmark-$i\"\n",
    "  BENCHMARK_ARCHIVE_PATH=\"benchmarks/$BENCHMARK_MERGE_REV/$i\"\n",
    "\n",
    "  echo \"$AGAVE_JOB_TEMPLATE\" | \\\n",
    "    jq --arg job_archive_path \"$BENCHMARK_ARCHIVE_PATH\" \\\n",
    "       --arg job_name $BENCHMARK_JOB_NAME \\\n",
    "       --arg job_input_dir $BENCHMARK_DIR \\\n",
    "       '. | .name=$job_name | .inputs.datafile=$job_input_dir | .archive=true | .archivePath=$job_archive_path' | \\\n",
    "    jobs-submit -F -\n",
    "\n",
    "done\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "### Updating analytics and published data  \n",
    "\n",
    "When your benchmarks complete, they can be published along with other app assets as metadata, archived with the benchmark jobs themselves, or saved as part of a document kept with the code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Control Systems  \n",
    "\n",
    "Let's just quickly acknowledge that we need to use some form of version control if we're going to talk about anything else related to proper software development in an open science community. The Good Enough recommendation says it all: \n",
    "\n",
    "> Use a version control system\n",
    "\n",
    "\n",
    "Using a version control system does not imply that everything should go in there. While Github, GitLab, and Bitbucket have large file support now, that does not mean we should commit large binary files without proper consideration.\n",
    "\n",
    "> Consider what not to put under version control \n",
    "\n",
    "As a rule of thumb, lean away from committing large binary docs and anyting that doens't lend itself well to text diffs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before we finish this notebook, let's go ahead and commit the changes to our repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remote in and commit the directory\n",
    "#ssh sandbox \"cd FUNWAVE_TVD && git add -A data && git commit -m 'Adding example dataset' .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will add the new files to version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=cd /home/jovyan/FUNWAVE-TVD && git add -A data CHANGELOG.md codemeta.json\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/s8ono0s8\n",
      "\n",
      " ** QUERY STRING FOR REQUESTBIN **\n",
      "https://requestbin.agaveapi.co/s8ono0s8?inspect\n",
      "\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-5058.txt\n",
      "Writing file `job-remote-5058.txt'\n",
      "OUTPUT=Successfully submitted job 1416183485880209896-242ac114-0001-007\n",
      "JOB_ID=1416183485880209896-242ac114-0001-007\n",
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=CLEANING_UP\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 1416183485880209896-242ac114-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r.runagavecmd('cd /home/jovyan/FUNWAVE-TVD && ' + \n",
    "              'git status && ' + \n",
    "              'git add -A data CHANGELOG.md codemeta.json && ' + \n",
    "              'git status  && ' + \n",
    "              'git commit -m \"Adding example dataset, changelog, and \"'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything succeeded, you should see your version number incremented and a build job now running in your job history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=ls /usr/install\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/1fzhazm1\n",
      "\n",
      " ** QUERY STRING FOR REQUESTBIN **\n",
      "https://requestbin.agaveapi.co/1fzhazm1?inspect\n",
      "\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-5058.txt\n",
      "Writing file `job-remote-5058.txt'\n",
      "OUTPUT=Successfully submitted job 5818937556024496616-242ac114-0001-007\n",
      "JOB_ID=5818937556024496616-242ac114-0001-007\n",
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=RUNNING\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 5818937556024496616-242ac114-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WITH the singularity check in the user's .profile and .bashrc files\n",
    "r.runagavecmd(\"ls /usr/install\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/usr/install': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get -P 5818937556024496616-242ac114-0001-007 fork-command-1.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=ls /usr/install\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/1880ovh1\n",
      "\n",
      " ** QUERY STRING FOR REQUESTBIN **\n",
      "https://requestbin.agaveapi.co/1880ovh1?inspect\n",
      "\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-5058.txt\n",
      "Writing file `job-remote-5058.txt'\n",
      "OUTPUT=Successfully submitted job 1163765710547775000-242ac114-0001-007\n",
      "JOB_ID=1163765710547775000-242ac114-0001-007\n",
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 1163765710547775000-242ac114-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT the singularity check in the user's .profile file\n",
    "r.runagavecmd(\"ls /usr/install\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/usr/install': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get -P 1163765710547775000-242ac114-0001-007 fork-command-1.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'sandbox,172.19.0.4' (ECDSA) to the list of known hosts.\n",
      "ls: cannot access '/usr/install': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ssh sandbox ls /usr/install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
